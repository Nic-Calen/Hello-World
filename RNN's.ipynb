{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start with exploring Deep Neural Networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Construction Phase:\n",
    "\n",
    "#specify inputs outputs number of neurons on each layer\n",
    "\n",
    "n_inputs = 28*28\n",
    "n_hidden1 =300\n",
    "n_hidden2 = 100\n",
    "n_outputs =10 \n",
    "\n",
    "#define our X and y placeholders size set to none for now b/c don't know training data size\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None , n_inputs) , name = \"X\")\n",
    "y = tf.placeholder(tf.int64, shape = (None),name = \"y\")\n",
    "\n",
    "\"\"\"X will act as the input layer, when executed it will be replaced with one\n",
    "training batch at a time\"\"\"\n",
    "\n",
    "#Create a function that will make one neuron layer at a time \n",
    "\n",
    "def neuron_layer(X, n_neurons, name, activation =None):\n",
    "    with tf.name_scope(name): #contains compuation nodes for neuron layer\n",
    "        n_inputs = int(X.get_shape()[1]) #find num rows in matrix (2nd dimension)\n",
    "        \n",
    "        #Create the weights matrix\n",
    "        \n",
    "        \"\"\"Weights matrix is a 2D tensor containing all the weights between\n",
    "        each neuron and each input. Hence shape is (n_inputs, n_neurons). Initi\n",
    "        -alized randomly using a normal distribution \"\"\"\n",
    "        stddev = 2 / np.sqrt(n_inputs) \n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev =stddev)\n",
    "        W = tf.Variable(init, name = \"kernel\")\n",
    "        \n",
    "        #Create biases\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name = \"bias\")\n",
    "        #compute weighted sums + biases for rach neuro in the layer\n",
    "        Z = tf.matmul(X,W)+b\n",
    "        \n",
    "        #Execute if a specific output activation is provided \n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z\n",
    "        \n",
    "\n",
    "#Create DNN!\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name = \"Hidden1\", activation = tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name = \"Hidden2\", activation = tf.nn.relu)\n",
    "    \n",
    "    logits = neuron_layer(hidden2, n_outputs, name = \"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y , logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name = \"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "#last step: specify how to evaluate the model \n",
    "\n",
    "#use accuracy as performance measure\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "\n",
    "#create node to initialize all variables and create a saver\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
